{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Data Ingestion and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Amina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "2025-01-23 14:22:12,118 - INFO - Processing C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Dataset\\2106.10270v2.pdf...\n",
      "2025-01-23 14:22:12,256 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_1.png\n",
      "2025-01-23 14:22:12,256 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_2.png\n",
      "2025-01-23 14:22:12,265 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_3.png\n",
      "2025-01-23 14:22:12,265 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_4.png\n",
      "2025-01-23 14:22:12,272 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_5.png\n",
      "2025-01-23 14:22:12,272 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_6.png\n",
      "2025-01-23 14:22:12,292 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_8_img_1.png\n",
      "2025-01-23 14:22:12,292 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_8_img_2.png\n",
      "2025-01-23 14:22:12,338 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_16_img_1.png\n",
      "2025-01-23 14:22:12,338 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_16_img_2.png\n",
      "2025-01-23 14:22:12,344 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_16_img_3.png\n",
      "2025-01-23 14:22:12,346 - INFO - Saved structured data to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\2106.10270v2.json\n",
      "2025-01-23 14:22:12,346 - INFO - Processing C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Dataset\\2112.13492v1.pdf...\n",
      "2025-01-23 14:22:13,077 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_1_img_1.png\n",
      "2025-01-23 14:22:14,057 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_1.png\n",
      "2025-01-23 14:22:14,202 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_2.png\n",
      "2025-01-23 14:22:14,353 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_1.png\n",
      "2025-01-23 14:22:14,391 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_2.png\n",
      "2025-01-23 14:22:19,037 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_8_img_1.png\n",
      "2025-01-23 14:22:19,399 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_11_img_1.png\n",
      "2025-01-23 14:22:19,405 - INFO - Saved structured data to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\2112.13492v1.json\n",
      "2025-01-23 14:22:19,408 - INFO - Processing C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Dataset\\2307.08461v3.pdf...\n",
      "2025-01-23 14:22:19,436 - INFO - Saved structured data to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\2307.08461v3.json\n",
      "2025-01-23 14:22:19,437 - INFO - Processing C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Dataset\\2310.05421v1.pdf...\n",
      "2025-01-23 14:22:19,488 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_2_img_1.png\n",
      "2025-01-23 14:22:19,591 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_1.png\n",
      "2025-01-23 14:22:19,592 - INFO - Saved structured data to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\2310.05421v1.json\n",
      "2025-01-23 14:22:19,592 - INFO - Processing C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Dataset\\2310.12069v2.pdf...\n",
      "2025-01-23 14:22:19,622 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_6_img_1.png\n",
      "2025-01-23 14:22:19,622 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_6_img_2.png\n",
      "2025-01-23 14:22:19,627 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_6_img_3.png\n",
      "2025-01-23 14:22:19,787 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_12_img_1.png\n",
      "2025-01-23 14:22:19,803 - INFO - Saved structured data to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\2310.12069v2.json\n",
      "2025-01-23 14:22:19,816 - INFO - Processing C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Dataset\\2401.04374v2.pdf...\n",
      "2025-01-23 14:22:19,855 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_2_img_1.png\n",
      "2025-01-23 14:22:19,865 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_2_img_2.png\n",
      "2025-01-23 14:22:19,865 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_2_img_3.png\n",
      "2025-01-23 14:22:19,875 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_2_img_4.png\n",
      "2025-01-23 14:22:19,875 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_2_img_5.png\n",
      "2025-01-23 14:22:19,875 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_2_img_6.png\n",
      "2025-01-23 14:22:19,875 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_2_img_7.png\n",
      "2025-01-23 14:22:19,888 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_2_img_8.png\n",
      "2025-01-23 14:22:19,958 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_1.png\n",
      "2025-01-23 14:22:19,985 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_2.png\n",
      "2025-01-23 14:22:20,021 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_3.png\n",
      "2025-01-23 14:22:20,064 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_4.png\n",
      "2025-01-23 14:22:20,105 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_5.png\n",
      "2025-01-23 14:22:20,155 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_6.png\n",
      "2025-01-23 14:22:20,180 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_7.png\n",
      "2025-01-23 14:22:20,199 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_8.png\n",
      "2025-01-23 14:22:20,222 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_9.png\n",
      "2025-01-23 14:22:20,271 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_10.png\n",
      "2025-01-23 14:22:20,307 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_11.png\n",
      "2025-01-23 14:22:20,342 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_12.png\n",
      "2025-01-23 14:22:20,370 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_13.png\n",
      "2025-01-23 14:22:20,413 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_14.png\n",
      "2025-01-23 14:22:20,455 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_15.png\n",
      "2025-01-23 14:22:20,508 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_16.png\n",
      "2025-01-23 14:22:20,553 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_17.png\n",
      "2025-01-23 14:22:20,593 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_18.png\n",
      "2025-01-23 14:22:20,629 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_19.png\n",
      "2025-01-23 14:22:20,659 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_20.png\n",
      "2025-01-23 14:22:20,698 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_21.png\n",
      "2025-01-23 14:22:20,738 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_22.png\n",
      "2025-01-23 14:22:20,785 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_23.png\n",
      "2025-01-23 14:22:20,821 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_24.png\n",
      "2025-01-23 14:22:20,825 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_25.png\n",
      "2025-01-23 14:22:20,828 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_26.png\n",
      "2025-01-23 14:22:20,828 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_27.png\n",
      "2025-01-23 14:22:20,828 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_28.png\n",
      "2025-01-23 14:22:20,850 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_6_img_1.png\n",
      "2025-01-23 14:22:20,850 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_6_img_2.png\n",
      "2025-01-23 14:22:20,855 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_6_img_3.png\n",
      "2025-01-23 14:22:20,859 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_6_img_4.png\n",
      "2025-01-23 14:22:20,863 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_6_img_5.png\n",
      "2025-01-23 14:22:20,863 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_6_img_6.png\n",
      "2025-01-23 14:22:20,905 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_9_img_1.png\n",
      "2025-01-23 14:22:20,914 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_9_img_2.png\n",
      "2025-01-23 14:22:20,927 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_9_img_3.png\n",
      "2025-01-23 14:22:20,938 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_9_img_4.png\n",
      "2025-01-23 14:22:20,955 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_9_img_5.png\n",
      "2025-01-23 14:22:20,963 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_9_img_6.png\n",
      "2025-01-23 14:22:20,972 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_9_img_7.png\n",
      "2025-01-23 14:22:21,011 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_9_img_8.png\n",
      "2025-01-23 14:22:21,021 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_9_img_9.png\n",
      "2025-01-23 14:22:21,046 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_9_img_10.png\n",
      "2025-01-23 14:22:21,070 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_9_img_11.png\n",
      "2025-01-23 14:22:21,086 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_9_img_12.png\n",
      "2025-01-23 14:22:21,098 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_9_img_13.png\n",
      "2025-01-23 14:22:21,107 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_9_img_14.png\n",
      "2025-01-23 14:22:21,122 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_9_img_15.png\n",
      "2025-01-23 14:22:21,122 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_9_img_16.png\n",
      "2025-01-23 14:22:21,122 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_9_img_17.png\n",
      "2025-01-23 14:22:21,144 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_9_img_18.png\n",
      "2025-01-23 14:22:21,258 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_10_img_1.png\n",
      "2025-01-23 14:22:21,271 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_10_img_2.png\n",
      "2025-01-23 14:22:21,288 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_10_img_3.png\n",
      "2025-01-23 14:22:21,316 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_10_img_4.png\n",
      "2025-01-23 14:22:21,338 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_10_img_5.png\n",
      "2025-01-23 14:22:21,372 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_10_img_6.png\n",
      "2025-01-23 14:22:21,410 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_10_img_7.png\n",
      "2025-01-23 14:22:21,488 - INFO - Saved structured data to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\2401.04374v2.json\n",
      "2025-01-23 14:22:21,494 - INFO - Processing C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Dataset\\2402.14474v1.pdf...\n",
      "2025-01-23 14:22:21,596 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_2_img_1.png\n",
      "2025-01-23 14:22:21,688 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_1.png\n",
      "2025-01-23 14:22:21,710 - INFO - Saved structured data to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\2402.14474v1.json\n",
      "2025-01-23 14:22:21,710 - INFO - Processing C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Dataset\\2402.18679v4.pdf...\n",
      "2025-01-23 14:22:22,002 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_2_img_1.png\n",
      "2025-01-23 14:22:22,191 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_1.png\n",
      "2025-01-23 14:22:22,191 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_2.png\n",
      "2025-01-23 14:22:22,191 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_3.png\n",
      "2025-01-23 14:22:22,202 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_4.png\n",
      "2025-01-23 14:22:22,202 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_5.png\n",
      "2025-01-23 14:22:22,271 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_6.png\n",
      "2025-01-23 14:22:22,282 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_7.png\n",
      "2025-01-23 14:22:22,318 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_8.png\n",
      "2025-01-23 14:22:22,323 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_9.png\n",
      "2025-01-23 14:22:22,326 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_10.png\n",
      "2025-01-23 14:22:22,330 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_11.png\n",
      "2025-01-23 14:22:22,330 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_12.png\n",
      "2025-01-23 14:22:22,336 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_13.png\n",
      "2025-01-23 14:22:22,338 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_14.png\n",
      "2025-01-23 14:22:22,344 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_15.png\n",
      "2025-01-23 14:22:22,346 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_16.png\n",
      "2025-01-23 14:22:22,347 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_17.png\n",
      "2025-01-23 14:22:22,360 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_18.png\n",
      "2025-01-23 14:22:22,379 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_19.png\n",
      "2025-01-23 14:22:22,388 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_20.png\n",
      "2025-01-23 14:22:22,405 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_1.png\n",
      "2025-01-23 14:22:22,405 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_2.png\n",
      "2025-01-23 14:22:22,413 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_3.png\n",
      "2025-01-23 14:22:22,413 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_4.png\n",
      "2025-01-23 14:22:22,413 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_5.png\n",
      "2025-01-23 14:22:22,422 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_6.png\n",
      "2025-01-23 14:22:22,422 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_7.png\n",
      "2025-01-23 14:22:22,422 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_8.png\n",
      "2025-01-23 14:22:22,430 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_9.png\n",
      "2025-01-23 14:22:22,430 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_10.png\n",
      "2025-01-23 14:22:22,430 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_11.png\n",
      "2025-01-23 14:22:22,435 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_12.png\n",
      "2025-01-23 14:22:22,438 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_13.png\n",
      "2025-01-23 14:22:22,439 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_14.png\n",
      "2025-01-23 14:22:22,444 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_15.png\n",
      "2025-01-23 14:22:22,446 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_16.png\n",
      "2025-01-23 14:22:22,449 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_17.png\n",
      "2025-01-23 14:22:22,450 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_18.png\n",
      "2025-01-23 14:22:22,455 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_19.png\n",
      "2025-01-23 14:22:22,522 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_9_img_1.png\n",
      "2025-01-23 14:22:22,658 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_10_img_1.png\n",
      "2025-01-23 14:22:23,908 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_16_img_1.png\n",
      "2025-01-23 14:22:24,456 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_24_img_1.png\n",
      "2025-01-23 14:22:24,655 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_24_img_2.png\n",
      "2025-01-23 14:22:24,804 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_25_img_1.png\n",
      "2025-01-23 14:22:24,958 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_25_img_2.png\n",
      "2025-01-23 14:22:24,982 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_26_img_1.png\n",
      "2025-01-23 14:22:25,021 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_26_img_2.png\n",
      "2025-01-23 14:22:25,042 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_26_img_3.png\n",
      "2025-01-23 14:22:25,071 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_27_img_1.png\n",
      "2025-01-23 14:22:25,096 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_27_img_2.png\n",
      "2025-01-23 14:22:25,107 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_27_img_3.png\n",
      "2025-01-23 14:22:25,132 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_28_img_1.png\n",
      "2025-01-23 14:22:25,146 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_28_img_2.png\n",
      "2025-01-23 14:22:25,146 - INFO - Saved structured data to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\2402.18679v4.json\n",
      "2025-01-23 14:22:25,154 - INFO - Processing C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Dataset\\2409.14924v1.pdf...\n",
      "2025-01-23 14:22:25,402 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_1.png\n",
      "2025-01-23 14:22:25,586 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_1.png\n",
      "2025-01-23 14:22:25,769 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_8_img_1.png\n",
      "2025-01-23 14:22:25,913 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_12_img_1.png\n",
      "2025-01-23 14:22:26,195 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_16_img_1.png\n",
      "2025-01-23 14:22:26,280 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_17_img_1.png\n",
      "2025-01-23 14:22:26,314 - INFO - Saved structured data to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\2409.14924v1.json\n",
      "2025-01-23 14:22:26,314 - INFO - Processing C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Dataset\\jiang-et-al-2022-predicting-protein-ligand-docking-structure-with-graph-neural-network (1) (2) (1).pdf...\n",
      "2025-01-23 14:22:26,425 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_1_img_1.png\n",
      "2025-01-23 14:22:26,444 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_1_img_2.png\n",
      "2025-01-23 14:22:26,530 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_1.png\n",
      "2025-01-23 14:22:26,540 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_2.png\n",
      "2025-01-23 14:22:26,543 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_3.png\n",
      "2025-01-23 14:22:26,545 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_4.png\n",
      "2025-01-23 14:22:26,548 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_5.png\n",
      "2025-01-23 14:22:26,556 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_6.png\n",
      "2025-01-23 14:22:26,558 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_7.png\n",
      "2025-01-23 14:22:26,565 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_8.png\n",
      "2025-01-23 14:22:26,571 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_9.png\n",
      "2025-01-23 14:22:26,574 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_10.png\n",
      "2025-01-23 14:22:26,577 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_11.png\n",
      "2025-01-23 14:22:26,588 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_12.png\n",
      "2025-01-23 14:22:26,593 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_13.png\n",
      "2025-01-23 14:22:26,600 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_14.png\n",
      "2025-01-23 14:22:26,605 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_15.png\n",
      "2025-01-23 14:22:26,608 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_16.png\n",
      "2025-01-23 14:22:26,610 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_17.png\n",
      "2025-01-23 14:22:26,621 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_18.png\n",
      "2025-01-23 14:22:26,626 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_3_img_19.png\n",
      "2025-01-23 14:22:26,658 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_1.png\n",
      "2025-01-23 14:22:26,658 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_2.png\n",
      "2025-01-23 14:22:26,678 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_3.png\n",
      "2025-01-23 14:22:26,678 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_4.png\n",
      "2025-01-23 14:22:26,685 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_5.png\n",
      "2025-01-23 14:22:26,693 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_6.png\n",
      "2025-01-23 14:22:26,693 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_7.png\n",
      "2025-01-23 14:22:26,693 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_8.png\n",
      "2025-01-23 14:22:26,702 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_9.png\n",
      "2025-01-23 14:22:26,705 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_10.png\n",
      "2025-01-23 14:22:26,705 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_11.png\n",
      "2025-01-23 14:22:26,839 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_6_img_1.png\n",
      "2025-01-23 14:22:26,857 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_10_img_1.png\n",
      "2025-01-23 14:22:26,869 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_10_img_2.png\n",
      "2025-01-23 14:22:26,872 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_10_img_3.png\n",
      "2025-01-23 14:22:26,875 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_10_img_4.png\n",
      "2025-01-23 14:22:26,875 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_10_img_5.png\n",
      "2025-01-23 14:22:26,880 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_10_img_6.png\n",
      "2025-01-23 14:22:26,880 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_10_img_7.png\n",
      "2025-01-23 14:22:26,885 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_10_img_8.png\n",
      "2025-01-23 14:22:26,888 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_10_img_9.png\n",
      "2025-01-23 14:22:26,894 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_10_img_10.png\n",
      "2025-01-23 14:22:26,896 - INFO - Saved structured data to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\jiang-et-al-2022-predicting-protein-ligand-docking-structure-with-graph-neural-network (1) (2) (1).json\n",
      "2025-01-23 14:22:26,901 - INFO - Processing C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Dataset\\Paper1.pdf...\n",
      "2025-01-23 14:22:26,946 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_1_img_1.png\n",
      "2025-01-23 14:22:26,962 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_1_img_2.png\n",
      "2025-01-23 14:22:26,971 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_1_img_3.png\n",
      "2025-01-23 14:22:27,038 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_1.png\n",
      "2025-01-23 14:22:27,079 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_5_img_1.png\n",
      "2025-01-23 14:22:27,303 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_6_img_1.png\n",
      "2025-01-23 14:22:27,704 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_1.png\n",
      "2025-01-23 14:22:28,007 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_9_img_1.png\n",
      "2025-01-23 14:22:28,284 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_10_img_1.png\n",
      "2025-01-23 14:22:28,386 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_11_img_1.png\n",
      "2025-01-23 14:22:28,603 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_12_img_1.png\n",
      "2025-01-23 14:22:28,635 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_12_img_2.png\n",
      "2025-01-23 14:22:28,788 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_14_img_1.png\n",
      "2025-01-23 14:22:28,837 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_14_img_2.png\n",
      "2025-01-23 14:22:28,848 - INFO - Saved structured data to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\Paper1.json\n",
      "2025-01-23 14:22:28,848 - INFO - Processing C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Dataset\\Paper2.pdf...\n",
      "2025-01-23 14:22:28,855 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_1_img_1.png\n",
      "2025-01-23 14:22:28,911 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_2_img_1.png\n",
      "2025-01-23 14:22:28,911 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_2_img_2.png\n",
      "2025-01-23 14:22:28,911 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_2_img_3.png\n",
      "2025-01-23 14:22:28,922 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_2_img_4.png\n",
      "2025-01-23 14:22:28,922 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_2_img_5.png\n",
      "2025-01-23 14:22:28,960 - INFO - Saved structured data to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\Paper2.json\n",
      "2025-01-23 14:22:28,960 - INFO - Processing C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Dataset\\Paper3.pdf...\n",
      "2025-01-23 14:22:28,988 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_1_img_1.png\n",
      "2025-01-23 14:22:29,010 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_1_img_2.png\n",
      "2025-01-23 14:22:29,010 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_1_img_3.png\n",
      "2025-01-23 14:22:29,115 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_4_img_1.png\n",
      "2025-01-23 14:22:29,171 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_1.png\n",
      "2025-01-23 14:22:29,213 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_2.png\n",
      "2025-01-23 14:22:29,277 - INFO - Saved image: C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\images\\page_7_img_3.png\n",
      "2025-01-23 14:22:29,288 - INFO - Saved structured data to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\\Paper3.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import fitz  # PyMuPDF for handling PDFs\n",
    "from nltk.tokenize import sent_tokenize  # For sentence tokenization\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "def extract_text_with_formatting(page):\n",
    "    \"\"\"\n",
    "    Extract paragraphs from a single PDF page, excluding the \"References\" section.\n",
    "    Args:\n",
    "        page (fitz.Page): A page object from the PDF.\n",
    "    Returns:\n",
    "        list: A list of sentences extracted from the page.\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "    references_detected = False  # Flag to detect the \"References\" section\n",
    "\n",
    "    for block in blocks:\n",
    "        if block[\"type\"] == 0:  # Only process text blocks\n",
    "            paragraph = \" \".join(\n",
    "                \" \".join(span[\"text\"] for span in line[\"spans\"]).strip()\n",
    "                for line in block[\"lines\"]\n",
    "            )\n",
    "\n",
    "            # Check if the paragraph contains the word \"References\" (case-insensitive)\n",
    "            if not references_detected and \"references\" in paragraph.lower():\n",
    "                references_detected = True\n",
    "                continue  # Skip the \"References\" heading and all subsequent content\n",
    "\n",
    "            if not references_detected and paragraph.strip():\n",
    "                # Tokenize the paragraph into sentences\n",
    "                sentences.extend(sent_tokenize(paragraph))\n",
    "\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def extract_images(page, output_dir, page_number):\n",
    "    \"\"\"\n",
    "    Extract images from a PDF page and save them to the output directory.\n",
    "    Args:\n",
    "        page (fitz.Page): A page object from the PDF.\n",
    "        output_dir (str): Directory to save the extracted images.\n",
    "        page_number (int): The page number (0-indexed).\n",
    "    Returns:\n",
    "        list: A list of image file paths.\n",
    "    \"\"\"\n",
    "    image_paths = []\n",
    "    for img_index, img in enumerate(page.get_images(full=True)):\n",
    "        xref = img[0]\n",
    "        pixmap = fitz.Pixmap(page.parent, xref)\n",
    "        image_filename = f\"page_{page_number + 1}_img_{img_index + 1}.png\"\n",
    "        image_path = os.path.join(output_dir, image_filename)\n",
    "        pixmap.save(image_path)\n",
    "        image_paths.append(image_path)\n",
    "        logging.info(f\"Saved image: {image_path}\")\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "\n",
    "def process_pdf(pdf_path, output_dir):\n",
    "    \"\"\"\n",
    "    Process a single PDF file and save structured data to the output directory.\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file.\n",
    "        output_dir (str): Directory to save structured data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        output_data = []\n",
    "\n",
    "        # Create a subdirectory for images\n",
    "        images_dir = os.path.join(output_dir, \"images\")\n",
    "        if not os.path.exists(images_dir):\n",
    "            os.makedirs(images_dir)\n",
    "\n",
    "        for page_number in range(len(doc)):\n",
    "            page = doc.load_page(page_number)\n",
    "            sentences = extract_text_with_formatting(page)\n",
    "            extract_images(page, images_dir, page_number)  # Extract images but don't store paths\n",
    "\n",
    "            page_data = {\n",
    "                'page_number': page_number + 1,\n",
    "                'sentences': sentences,  # Store sentences\n",
    "            }\n",
    "            output_data.append(page_data)\n",
    "\n",
    "        json_filename = os.path.splitext(os.path.basename(pdf_path))[0] + '.json'\n",
    "        json_path = os.path.join(output_dir, json_filename)\n",
    "        with open(json_path, 'w', encoding='utf-8') as json_file:\n",
    "            json.dump(output_data, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "        logging.info(f\"Saved structured data to {json_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {pdf_path}: {e}\")\n",
    "\n",
    "\n",
    "def process_pdfs_in_directory(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Process all PDF files in the input directory and save structured data to the output directory.\n",
    "    Args:\n",
    "        input_dir (str): Path to the directory containing PDF files.\n",
    "        output_dir (str): Path to the directory to save structured data.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    pdf_files = [f for f in os.listdir(input_dir) if f.endswith('.pdf')]\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(input_dir, pdf_file)\n",
    "        logging.info(f\"Processing {pdf_path}...\")\n",
    "        process_pdf(pdf_path, output_dir)\n",
    "\n",
    "\n",
    "# Example Usage for Extraction\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_directory = r\"C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Dataset\"\n",
    "    extracted_directory = r\"C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\"\n",
    "\n",
    "    # Step 1: Extract data from PDFs\n",
    "    process_pdfs_in_directory(pdf_directory, extracted_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Cleaning and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Amina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Amina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2025-01-23 14:32:39,323 - INFO - Processing 2106.10270v2.json...\n",
      "2025-01-23 14:32:39,522 - INFO - Cleaned data saved to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Cleaneddataset\\2106.10270v2.json\n",
      "2025-01-23 14:32:39,522 - INFO - Processing 2112.13492v1.json...\n",
      "2025-01-23 14:32:39,657 - INFO - Cleaned data saved to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Cleaneddataset\\2112.13492v1.json\n",
      "2025-01-23 14:32:39,657 - INFO - Processing 2307.08461v3.json...\n",
      "2025-01-23 14:32:39,673 - INFO - Cleaned data saved to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Cleaneddataset\\2307.08461v3.json\n",
      "2025-01-23 14:32:39,673 - INFO - Processing 2310.05421v1.json...\n",
      "2025-01-23 14:32:39,735 - INFO - Cleaned data saved to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Cleaneddataset\\2310.05421v1.json\n",
      "2025-01-23 14:32:39,738 - INFO - Processing 2310.12069v2.json...\n",
      "2025-01-23 14:32:39,811 - INFO - Cleaned data saved to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Cleaneddataset\\2310.12069v2.json\n",
      "2025-01-23 14:32:39,811 - INFO - Processing 2401.04374v2.json...\n",
      "2025-01-23 14:32:39,979 - INFO - Cleaned data saved to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Cleaneddataset\\2401.04374v2.json\n",
      "2025-01-23 14:32:39,979 - INFO - Processing 2402.14474v1.json...\n",
      "2025-01-23 14:32:40,026 - INFO - Cleaned data saved to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Cleaneddataset\\2402.14474v1.json\n",
      "2025-01-23 14:32:40,037 - INFO - Processing 2402.18679v4.json...\n",
      "2025-01-23 14:32:40,167 - INFO - Cleaned data saved to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Cleaneddataset\\2402.18679v4.json\n",
      "2025-01-23 14:32:40,171 - INFO - Processing 2409.14924v1.json...\n",
      "2025-01-23 14:32:40,245 - INFO - Cleaned data saved to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Cleaneddataset\\2409.14924v1.json\n",
      "2025-01-23 14:32:40,245 - INFO - Processing jiang-et-al-2022-predicting-protein-ligand-docking-structure-with-graph-neural-network (1) (2) (1).json...\n",
      "2025-01-23 14:32:40,339 - INFO - Cleaned data saved to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Cleaneddataset\\jiang-et-al-2022-predicting-protein-ligand-docking-structure-with-graph-neural-network (1) (2) (1).json\n",
      "2025-01-23 14:32:40,339 - INFO - Processing Paper1.json...\n",
      "2025-01-23 14:32:40,420 - INFO - Cleaned data saved to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Cleaneddataset\\Paper1.json\n",
      "2025-01-23 14:32:40,429 - INFO - Processing Paper2.json...\n",
      "2025-01-23 14:32:40,479 - INFO - Cleaned data saved to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Cleaneddataset\\Paper2.json\n",
      "2025-01-23 14:32:40,479 - INFO - Processing Paper3.json...\n",
      "2025-01-23 14:32:40,606 - INFO - Cleaned data saved to C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Cleaneddataset\\Paper3.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import logging\n",
    "from nltk.tokenize import sent_tokenize  # For sentence tokenization\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "# Ensure NLTK resources are available\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "def clean_sentence(sentence):\n",
    "    \"\"\"\n",
    "    Cleans a sentence by removing URLs, punctuation, and stopwords.\n",
    "    Args:\n",
    "        sentence (str): The sentence to clean.\n",
    "    Returns:\n",
    "        str: The cleaned sentence.\n",
    "    \"\"\"\n",
    "    # Remove URLs using a robust regex pattern\n",
    "    sentence = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", sentence, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    sentence = re.sub(f\"[{re.escape(punctuation)}]\", \"\", sentence)\n",
    "    \n",
    "    # Lowercase the text\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    cleaned_sentence = \" \".join(word for word in sentence.split() if word not in stop_words)\n",
    "    \n",
    "    return cleaned_sentence\n",
    "\n",
    "\n",
    "def clean_json_file(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Cleans sentences in a JSON file and saves the cleaned data.\n",
    "    Args:\n",
    "        input_path (str): Path to the input JSON file.\n",
    "        output_path (str): Path to save the cleaned JSON file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(input_path, 'r', encoding='utf-8') as infile:\n",
    "            data = json.load(infile)\n",
    "\n",
    "        for page in data:\n",
    "            page['sentences'] = [clean_sentence(sentence) for sentence in page.get('sentences', [])]\n",
    "\n",
    "        with open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "            json.dump(data, outfile, indent=4, ensure_ascii=False)\n",
    "\n",
    "        logging.info(f\"Cleaned data saved to {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error cleaning {input_path}: {e}\")\n",
    "\n",
    "\n",
    "def process_directory(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Processes all JSON files in a directory, cleaning them and saving the results.\n",
    "    Args:\n",
    "        input_dir (str): Path to the directory containing JSON files.\n",
    "        output_dir (str): Path to save cleaned JSON files.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    json_files = [f for f in os.listdir(input_dir) if f.endswith('.json')]\n",
    "\n",
    "    for json_file in json_files:\n",
    "        input_path = os.path.join(input_dir, json_file)\n",
    "        output_path = os.path.join(output_dir, json_file)\n",
    "        logging.info(f\"Processing {json_file}...\")\n",
    "        clean_json_file(input_path, output_path)\n",
    "\n",
    "\n",
    "# Example Usage for Cleaning and Tokenization\n",
    "if __name__ == \"__main__\":\n",
    "    extracted_directory = r\"C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Extracteddataset\"\n",
    "    cleaned_directory = r\"C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Cleaneddataset\"\n",
    "\n",
    "    # Step 2: Clean the extracted data\n",
    "    process_directory(extracted_directory, cleaned_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 (Load and Parse JSON Files), Step 2 (Generate Embeddings), and Step 3 (Index the Embeddings),+Retrieve Relevant Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and parsing JSON files...\n",
      "Loaded 168 text chunks.\n",
      "Generating embeddings...\n",
      "Embeddings generated.\n",
      "Indexing embeddings...\n",
      "Embeddings indexed.\n",
      "Query: What is the vision transformer?\n",
      "Top 3 results:\n",
      "Result 1: Page 1\n",
      "Text: vision transformer smallsize datasets seung hoon lee inha university incheon south korea aanna0701gmailcom seunghyun lee inha university incheon south korea lsh910703gmailcom byung cheol song inha university incheon south korea bcsonginhaackr abstract recently vision transformer vit applied transformer structure image classication task outperformed convolutional neural networks however high performance vit results pretraining using largesize dataset jft300m depen dence large dataset interpreted due low locality inductive bias paper proposes shifted patch tokeniza tion spt locality selfattention lsa effec tively solve lack locality inductive bias enable learn scratch even smallsize datasets moreover spt lsa generic effective addon modules easily applicable various vits experimental results show spt lsa applied vits performance improved average 2 96 tiny imagenet representative smallsize dataset es pecially swin transformer achieved overwhelming per formance improvement 4 08 thanks proposed spt lsa 1 introduction convolutional neural networks cnns ef fective learning visual representations image data mainstream eld computer vision cv 10 14 18 30 32 37 meanwhile eld natural language processing nlp socalled trans former 35 based selfattention mechanism achieved tremendous success 5 8 20 cv eld attempts combine selfattention mechanism cnns 4 13 28 36 38 44 studies succeeded proving selfattention mechanism also works image domain recently reported vision trans former vit 9 applied standard transformer composed entirely selfattention image data showed better performance resnet 10 efcientnet 32 image classication task made transformer ceive lot attention cv eld vit rarely uses convolutional lters ie core figure 1 effect proposed method overall perfor mance learning tinyimagenet scratch throughput refers many images processed per unit time stars dots indicate proposed method applied respectively cnns convolutional lters usually used tokenization thus vit structurally lacks locality inductive bias cnns require large amount training data obtain acceptable visual representation 26 example learn smallsize dataset vit precede pretraining largesize dataset jft 300m 29 order alleviate burden pretraining several vits learn midsize dataset ima genet scratch proposed dataefcient vits tried increase locality inductive bias terms network architecture example adopted hi erarchical structure like cnns leverage various recep tive elds 12 24 39 others tried modify selfattention mechanism 22 24 34 39 40 however learning scratch midsize datasets still requires sig nicant costs moreover learning smallsize datasets arxiv211213492v1 cscv 27 dec 2021\n",
      "\n",
      "Result 2: Page 10\n",
      "Text:      1 h h  1 h   2 17 redefining output every hidden unit  h  h    18  trainable parameter layer normalization improves training time generalization performance transformer  multilayer perceptron mlp single mlp feedforward neural net applied inde pendently output vector layer normalization adding layer increases capability model without increasing computational complexity mlp acts position independently attention mechanism already learned correlations across positions result additional nonlinearity model transformer able learn patterns relationships data thats covered main elements transformer block able understand construction complicated transformerbased architectures models like original transformer encoderdecoder model gpt family etc faqs point good starting point implement transformer discussed topics including pretraining selfsupervised vs unsupervised training computational issues others emerged use transformers issues briefly discussed next section astronomical applications others faqs following section 4 transformers astronomy sequential data time domain astronomy numerical counterpart nlp tackled using transformers several recent studies discussed first subsection image analysis problems large datasets occur variety settings astronomy cosmology second subsection summarizes applications vits image analysis concludes multimodal datasets astronomy section assumes familiarity astronomical surveys deep learning 41 time series data timevarying light sources astronomical transients variables often described terms light curves brightness time time series natural applica tion sequence modeling architectures like transformers prevalence measurement noise irregular sampling makes unique challenge textfocused models number recent works explored applications broadly categorized terms architectures training procedures 10\n",
      "\n",
      "Result 3: Page 1\n",
      "Text: transformers scientific data pedagogical review astronomers dimitrios tanoglidis bhuvnesh jain helen qu university pennsylvania abstract deep learning architecture associated chatgpt related generative ai products known transformer initially applied natural language processing transformers selfattention mechanism exploit gained widespread interest across natural sciences goal pedagogical informal review introduce transformers scientists review includes mathematics underlying attention mechanism description original transformer architecture section applications time series imaging data astronomy include frequently asked questions section readers curious generative ai interested getting started transformers research problem 1 introduction short pedagogical set notes attention mechanism deep learning architecture utilizes mechanism transformers transformers revolutionized natural language processing nlp recently also emerged powerful paradigm computer vision applications vision transformers vits generally imaging multimodal datasets sciences transformerbased architectures behind ai applications made news recently including large language models llms like gpt imagefromtext generators like dalle goal short review introduce scientists astronomers particular transformers notes intended quick start mathematically oriented scientists focus understanding main concepts math behind selfattention mechanism transformer block fundamental building block transformerbased architectures present key equations underlying attention mechanism describe complete architecture model large language models bert gpt trained furthermore start exploration medias res showing modern selfattention mechanism omitting historical introduction attention mechanism part recurrent neural network model also cover variations attention mechanism developed variety applications key property selfattention allows transformers capture longrange dependencies without sequential processing parallelizing training process simultane ously avoiding vanishing gradient problems means sequential data setting 1 arxiv231012069v2 astrophim 19 oct 2023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Step 1: Load and Parse JSON Files\n",
    "def load_and_parse_json_files(directory):\n",
    "    \"\"\"\n",
    "    Load JSON files from the directory and combine sentences into chunks.\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".json\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "                #print(f\"Loaded JSON file: {filename}\")\n",
    "                #print(f\"Structure: {data}\")  # Debug: Print the structure of the JSON file\n",
    "                documents.append(data)\n",
    "\n",
    "    # Combine sentences into chunks (e.g., by page)\n",
    "    text_chunks = []\n",
    "    for doc in documents:\n",
    "        # Debug: Print the structure of each document\n",
    "        #print(f\"Document structure: {doc}\")\n",
    "        \n",
    "        # Check if the document is a list or a dictionary\n",
    "        if isinstance(doc, list):\n",
    "            # If the document is a list, iterate through it\n",
    "            for item in doc:\n",
    "                page_number = item.get(\"page_number\", \"Unknown\")  # Use .get() to avoid KeyError\n",
    "                sentences = item.get(\"sentences\", [])  # Use .get() to avoid KeyError\n",
    "                chunk = \" \".join(sentences)  # Combine sentences into a single chunk\n",
    "                text_chunks.append({\n",
    "                    \"page_number\": page_number,\n",
    "                    \"text\": chunk\n",
    "                })\n",
    "        elif isinstance(doc, dict):\n",
    "            # If the document is a dictionary, process it directly\n",
    "            page_number = doc.get(\"page_number\", \"Unknown\")  # Use .get() to avoid KeyError\n",
    "            sentences = doc.get(\"sentences\", [])  # Use .get() to avoid KeyError\n",
    "            chunk = \" \".join(sentences)  # Combine sentences into a single chunk\n",
    "            text_chunks.append({\n",
    "                \"page_number\": page_number,\n",
    "                \"text\": chunk\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Unexpected document format: {type(doc)}\")\n",
    "    \n",
    "    return text_chunks\n",
    "\n",
    "# Step 2: Generate Embeddings\n",
    "def generate_embeddings(text_chunks):\n",
    "    \"\"\"\n",
    "    Generate embeddings for the text chunks using Sentence-BERT.\n",
    "    \"\"\"\n",
    "    # Load a pre-trained embedding model\n",
    "    embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    # Extract text from chunks\n",
    "    texts = [chunk[\"text\"] for chunk in text_chunks]\n",
    "\n",
    "    # Generate embeddings for all text chunks\n",
    "    embeddings = embedding_model.encode(texts)\n",
    "    \n",
    "    return embeddings, embedding_model\n",
    "\n",
    "# Step 3: Index the Embeddings with Cosine Similarity\n",
    "def index_embeddings(embeddings):\n",
    "    \"\"\"\n",
    "    Index the embeddings using FAISS with cosine similarity.\n",
    "    \"\"\"\n",
    "    # Normalize embeddings to unit vectors (required for cosine similarity)\n",
    "    embeddings = np.array(embeddings).astype('float32')\n",
    "    faiss.normalize_L2(embeddings)  # Normalize embeddings\n",
    "\n",
    "    # Create a FAISS index for cosine similarity\n",
    "    dimension = embeddings.shape[1]  # Dimension of the embeddings\n",
    "    index = faiss.IndexFlatIP(dimension)  # Inner product (cosine similarity)\n",
    "    index.add(embeddings)  # Add embeddings to the index\n",
    "    \n",
    "    return index\n",
    "\n",
    "# Step 4: Retrieve Relevant Documents\n",
    "def retrieve_documents(query, embedding_model, index, text_chunks, top_k=3):\n",
    "    \"\"\"\n",
    "    Retrieve the most relevant documents for a given query using cosine similarity.\n",
    "    \"\"\"\n",
    "    # Generate embedding for the query\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    query_embedding = np.array(query_embedding).astype('float32')\n",
    "    faiss.normalize_L2(query_embedding)  # Normalize query embedding\n",
    "\n",
    "    # Search the FAISS index\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "\n",
    "    # Retrieve the relevant text chunks\n",
    "    results = []\n",
    "    for idx in indices[0]:\n",
    "        results.append(text_chunks[idx])\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Main function to execute all steps\n",
    "def main():\n",
    "    # Directory containing cleaned JSON files\n",
    "    cleaned_directory = r\"C:\\Users\\Amina\\Downloads\\freelanceProject\\CHatbotUrgent\\Cleaneddataset\"\n",
    "\n",
    "    # Step 1: Load and parse JSON files\n",
    "    print(\"Loading and parsing JSON files...\")\n",
    "    text_chunks = load_and_parse_json_files(cleaned_directory)\n",
    "    print(f\"Loaded {len(text_chunks)} text chunks.\")\n",
    "\n",
    "    # Step 2: Generate embeddings\n",
    "    print(\"Generating embeddings...\")\n",
    "    embeddings, embedding_model = generate_embeddings(text_chunks)\n",
    "    print(\"Embeddings generated.\")\n",
    "\n",
    "    # Step 3: Index embeddings with cosine similarity\n",
    "    print(\"Indexing embeddings...\")\n",
    "    index = index_embeddings(embeddings)\n",
    "    print(\"Embeddings indexed.\")\n",
    "\n",
    "    # Step 4: Retrieve relevant documents for a query\n",
    "    query = \"What is the vision transformer?\"\n",
    "    print(f\"Query: {query}\")\n",
    "\n",
    "    # Retrieve the top-k relevant documents\n",
    "    top_k = 3\n",
    "    relevant_chunks = retrieve_documents(query, embedding_model, index, text_chunks, top_k)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Top {top_k} results:\")\n",
    "    for i, chunk in enumerate(relevant_chunks):\n",
    "        print(f\"Result {i+1}: Page {chunk['page_number']}\")\n",
    "        print(f\"Text: {chunk['text']}\\n\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index loaded successfully.\n",
      "Embedding model loaded successfully.\n",
      "Loaded 168 text chunks from directory.\n",
      "LLaMA 3.2 model ready\n",
      "Error retrieving context: \n",
      "Retrieved Context:\n",
      "None\n",
      "\n",
      "Summary:\n",
      "The vision transformer (ViT) is a neural network architecture that processes visual data efficiently using self-attention mechanisms. It was introduced in 2020 and has become popular for image classification tasks due to its ability to capture long-range dependencies. ViT uses this compact representation to transform visual features into a useful output.\n",
      "\n",
      "Answer:\n",
      "The vision transformer (ViT) is a type of neural network architecture that uses self-attention mechanisms to process visual data efficiently, capturing long-range dependencies and contextual information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import ollama\n",
    "\n",
    "# Step 1: Load the FAISS index and embedding model\n",
    "def load_faiss_index(index_path):\n",
    "    try:\n",
    "        index = faiss.read_index(index_path)\n",
    "        print(\"FAISS index loaded successfully.\")\n",
    "        return index\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading FAISS index: {e}\")\n",
    "        raise\n",
    "\n",
    "def load_embedding_model():\n",
    "    try:\n",
    "        embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        print(\"Embedding model loaded successfully.\")\n",
    "        return embedding_model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading embedding model: {e}\")\n",
    "        raise\n",
    "\n",
    "# Step 2: Load all JSON files from a directory\n",
    "def load_text_chunks_from_directory(directory_path):\n",
    "    text_chunks = []\n",
    "    try:\n",
    "        for file_name in os.listdir(directory_path):\n",
    "            if file_name.endswith('.json'):\n",
    "                file_path = os.path.join(directory_path, file_name)\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:  # Explicitly use UTF-8\n",
    "                    data = json.load(file)\n",
    "                    if isinstance(data, list):\n",
    "                        text_chunks.extend(data)\n",
    "        print(f\"Loaded {len(text_chunks)} text chunks from directory.\")\n",
    "        return text_chunks\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading text chunks from directory: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Step 3: Retrieve context using FAISS index\n",
    "def retrieve_context(query, embedding_model, index, text_chunks, top_k=3):\n",
    "    try:\n",
    "        query_embedding = embedding_model.encode([query])\n",
    "        query_embedding = np.array(query_embedding).astype('float32')\n",
    "        faiss.normalize_L2(query_embedding)\n",
    "\n",
    "        distances, indices = index.search(query_embedding, top_k)\n",
    "        context = \"\\n\".join([text_chunks[idx][\"text\"] for idx in indices[0]])\n",
    "        return context\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving context: {e}\")\n",
    "        return None\n",
    "\n",
    "# Step 4: Load the LLaMA model using Ollama\n",
    "def load_llama_model():\n",
    "    try:\n",
    "        models = ollama.list()\n",
    "        model_list = models.get('models', [])\n",
    "        model_names = [model.get('model') for model in model_list]\n",
    "        \n",
    "        if \"llama3.2:latest\" not in model_names:\n",
    "            print(\"Downloading LLaMA 3.2 model...\")\n",
    "            ollama.pull(\"llama3.2:latest\")\n",
    "        print(\"LLaMA 3.2 model ready\")\n",
    "    except Exception as e:\n",
    "        print(f\"Model loading failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Step 5: Generate response using retrieved context\n",
    "def generate_response(context, question):\n",
    "    try:\n",
    "        prompt = f\"\"\"Perform these tasks on the text below:\n",
    "        1. Summarize in 3 sentences\n",
    "        2. Answer: {question}\n",
    "\n",
    "        Text: {context}\n",
    "\n",
    "        Format exactly as:\n",
    "        Summary: <summary>\n",
    "        Answer: <answer>\"\"\"\n",
    "\n",
    "        response = ollama.generate(\n",
    "            model=\"llama3.2:latest\",\n",
    "            prompt=prompt,\n",
    "            options={\"temperature\": 0.3}\n",
    "        )\n",
    "        return parse_response(response[\"response\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Step 6: Parse the response\n",
    "def parse_response(response):\n",
    "    summary, answer = None, None\n",
    "    lines = response.split(\"\\n\")\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"Summary:\"):\n",
    "            summary = line.split(\"Summary:\", 1)[1].strip()\n",
    "        elif line.startswith(\"Answer:\"):\n",
    "            answer = line.split(\"Answer:\", 1)[1].strip()\n",
    "    if not summary or not answer:\n",
    "        print(\"Warning: Response format incorrect\")\n",
    "    return summary, answer\n",
    "\n",
    "# Main workflow\n",
    "def main():\n",
    "    # File paths\n",
    "    faiss_index_path = \"faiss_index_cosine.index\"  # Replace with your FAISS index path\n",
    "    directory_path = \"C:\\\\Users\\\\Amina\\\\Downloads\\\\freelanceProject\\\\CHatbotUrgent\\\\Cleaneddataset\"  # JSON files directory\n",
    "\n",
    "    # Load FAISS index, embedding model, and text chunks\n",
    "    index = load_faiss_index(faiss_index_path)\n",
    "    embedding_model = load_embedding_model()\n",
    "    text_chunks = load_text_chunks_from_directory(directory_path)\n",
    "\n",
    "    # Load the LLaMA model\n",
    "    load_llama_model()\n",
    "\n",
    "    # Retrieve context and generate response\n",
    "    query = \"What is the vision transformer?\"  # Replace with your query\n",
    "    context = retrieve_context(query, embedding_model, index, text_chunks, top_k=3)\n",
    "    print(f\"Retrieved Context:\\n{context}\\n\")\n",
    "\n",
    "    summary, answer = generate_response(context, query)\n",
    "    if summary is not None and answer is not None:\n",
    "        print(f\"Summary:\\n{summary}\\n\")\n",
    "        print(f\"Answer:\\n{answer}\\n\")\n",
    "    else:\n",
    "        print(\"Failed to generate summary and answer.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
